{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validare una rete neurale\n",
    "Il processo di validazione di una rete neurale è importante per evitare che un modello possa andare in contro ad overfitting sul set di test. Questo è un problema più raro rispetto all'overfitting sul set di addestramento, ma che può verficarsi quando testiamo diversi modelli alla ricerca degli iperparametri migliori.\n",
    "<br>\n",
    "Una soluzione per affrontare questo problema consiste nel creare un terzo set apposito per la validazione, quindi avremo i seguenti set:\n",
    " * **Set di addestramento**: contiene gli esempi utilizzati per addestrare la rete.\n",
    " * **Set di validazione**: contiene gli esempi per validare ottimizzare gli iperparametri evitando l'overfitting.\n",
    " * **Set di test**: contiene gli esempi per testare il modello finale per verificarne la capacità predittiva.\n",
    " \n",
    "Vediamo come utilizzare un set di validazione utilizzando Keras e la nostra rete addestrata con l'IMDB Movie Review dataset.\n",
    "<br><br>\n",
    "Importiamo i moduli necessari."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.datasets import imdb \n",
    "from keras.regularizers import l2\n",
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carichiamo e prepariamo il dataset, inizialmente suddividendolo solo in set di addestramento e test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 5000)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=5000)\n",
    "\n",
    "def onehot_encoding(data, size):\n",
    "    onehot = np.zeros((len(data), size))\n",
    "    for i, d in enumerate(data):\n",
    "        onehot[i,d] = 1.\n",
    "    return onehot\n",
    "\n",
    "X_train = onehot_encoding(X_train, 5000)\n",
    "X_test = onehot_encoding(X_test, 5000)\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definiamo l'architettura della nostra rete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation='relu', input_shape=(5000,), kernel_regularizer=l2(0.1)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(128,activation='relu', kernel_regularizer=l2(0.01)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(32,activation='relu',kernel_regularizer=l2(0.001)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(8,activation='relu', kernel_regularizer=l2(0.01)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per utilizzare un set di validazione con Keras abbiamo due opzioni."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opzione 1: Definire manualmente un set di validazione"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creiamo il modello e compiliamolo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "model.compile(optimizer='adamax', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creiamo un set di validazione, estraendo gli ultimi 2500 esempi dal set di addestramento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esempi nel set di addestramento: 22500 \n",
      "Esempi nel set di validazione: 2500 \n",
      "Esempi nel set di test: 25000 \n"
     ]
    }
   ],
   "source": [
    "X_train2 = X_train[:-2500]\n",
    "y_train2 = y_train[:-2500]\n",
    "X_val = X_train[-2500:]\n",
    "y_val = y_train[-2500:]\n",
    "print(\"Esempi nel set di addestramento: %d \" % X_train2.shape[0])\n",
    "print(\"Esempi nel set di validazione: %d \" % X_val.shape[0])\n",
    "print(\"Esempi nel set di test: %d \" % X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adesso possiamo avviare l'addestramento passando il set di addestramento così creato all'interno del parametro <span style=\"font-family: Monaco\">validation_data</span> del metodo <span style=\"font-family: Monaco\">fit</span>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22500 samples, validate on 2500 samples\n",
      "Epoch 1/100\n",
      "22500/22500 [==============================] - 4s 200us/step - loss: 13.4928 - acc: 0.5155 - val_loss: 1.3383 - val_acc: 0.6944\n",
      "Epoch 2/100\n",
      "22500/22500 [==============================] - 4s 164us/step - loss: 0.9331 - acc: 0.6074 - val_loss: 0.7812 - val_acc: 0.8148\n",
      "Epoch 3/100\n",
      "22500/22500 [==============================] - 4s 165us/step - loss: 0.7469 - acc: 0.7164 - val_loss: 0.6809 - val_acc: 0.8512\n",
      "Epoch 4/100\n",
      "22500/22500 [==============================] - 4s 162us/step - loss: 0.7185 - acc: 0.8007 - val_loss: 0.6716 - val_acc: 0.8384\n",
      "Epoch 5/100\n",
      "22500/22500 [==============================] - 4s 167us/step - loss: 0.7027 - acc: 0.8295 - val_loss: 0.6338 - val_acc: 0.8640\n",
      "Epoch 6/100\n",
      "22500/22500 [==============================] - 4s 172us/step - loss: 0.6800 - acc: 0.8359 - val_loss: 0.6181 - val_acc: 0.8604\n",
      "Epoch 7/100\n",
      "22500/22500 [==============================] - 4s 176us/step - loss: 0.6660 - acc: 0.8398 - val_loss: 0.5975 - val_acc: 0.8688\n",
      "Epoch 8/100\n",
      "22500/22500 [==============================] - 4s 178us/step - loss: 0.6553 - acc: 0.8444 - val_loss: 0.5883 - val_acc: 0.8708\n",
      "Epoch 9/100\n",
      "22500/22500 [==============================] - 4s 178us/step - loss: 0.6457 - acc: 0.8444 - val_loss: 0.5763 - val_acc: 0.8756\n",
      "Epoch 10/100\n",
      "22500/22500 [==============================] - 4s 173us/step - loss: 0.6336 - acc: 0.8457 - val_loss: 0.5643 - val_acc: 0.8728\n",
      "Epoch 11/100\n",
      "22500/22500 [==============================] - 4s 178us/step - loss: 0.6189 - acc: 0.8512 - val_loss: 0.5571 - val_acc: 0.8692\n",
      "Epoch 12/100\n",
      "22500/22500 [==============================] - 4s 179us/step - loss: 0.6084 - acc: 0.8510 - val_loss: 0.5626 - val_acc: 0.8612\n",
      "Epoch 13/100\n",
      "22500/22500 [==============================] - 4s 182us/step - loss: 0.6110 - acc: 0.8498 - val_loss: 0.5476 - val_acc: 0.8712\n",
      "Epoch 14/100\n",
      "22500/22500 [==============================] - 4s 187us/step - loss: 0.5941 - acc: 0.8541 - val_loss: 0.5407 - val_acc: 0.8704\n",
      "Epoch 15/100\n",
      "22500/22500 [==============================] - 4s 186us/step - loss: 0.5819 - acc: 0.8567 - val_loss: 0.5482 - val_acc: 0.8664\n",
      "Epoch 16/100\n",
      "22500/22500 [==============================] - 4s 179us/step - loss: 0.5806 - acc: 0.8601 - val_loss: 0.5302 - val_acc: 0.8708\n",
      "Epoch 17/100\n",
      "22500/22500 [==============================] - 4s 178us/step - loss: 0.5692 - acc: 0.8606 - val_loss: 0.5341 - val_acc: 0.8708\n",
      "Epoch 18/100\n",
      "22500/22500 [==============================] - 4s 181us/step - loss: 0.5676 - acc: 0.8600 - val_loss: 0.5131 - val_acc: 0.8760\n",
      "Epoch 19/100\n",
      "22500/22500 [==============================] - 4s 182us/step - loss: 0.5650 - acc: 0.8596 - val_loss: 0.5041 - val_acc: 0.8836\n",
      "Epoch 20/100\n",
      "22500/22500 [==============================] - 4s 182us/step - loss: 0.5523 - acc: 0.8641 - val_loss: 0.5050 - val_acc: 0.8796\n",
      "Epoch 21/100\n",
      "22500/22500 [==============================] - 4s 182us/step - loss: 0.5473 - acc: 0.8665 - val_loss: 0.4992 - val_acc: 0.8788\n",
      "Epoch 22/100\n",
      "22500/22500 [==============================] - 4s 181us/step - loss: 0.5391 - acc: 0.8678 - val_loss: 0.5023 - val_acc: 0.8784\n",
      "Epoch 23/100\n",
      "22500/22500 [==============================] - 4s 182us/step - loss: 0.5362 - acc: 0.8668 - val_loss: 0.5012 - val_acc: 0.8784\n",
      "Epoch 24/100\n",
      "22500/22500 [==============================] - 4s 175us/step - loss: 0.5327 - acc: 0.8690 - val_loss: 0.4891 - val_acc: 0.8768\n",
      "Epoch 25/100\n",
      "22500/22500 [==============================] - 4s 185us/step - loss: 0.5276 - acc: 0.8663 - val_loss: 0.4985 - val_acc: 0.8792\n",
      "Epoch 26/100\n",
      "22500/22500 [==============================] - 4s 188us/step - loss: 0.5322 - acc: 0.8684 - val_loss: 0.4923 - val_acc: 0.8812\n",
      "Epoch 27/100\n",
      "22500/22500 [==============================] - 4s 180us/step - loss: 0.5292 - acc: 0.8683 - val_loss: 0.4997 - val_acc: 0.8732\n",
      "Epoch 28/100\n",
      "22500/22500 [==============================] - 4s 183us/step - loss: 0.5333 - acc: 0.8633 - val_loss: 0.4869 - val_acc: 0.8808\n",
      "Epoch 29/100\n",
      "22500/22500 [==============================] - 4s 175us/step - loss: 0.5199 - acc: 0.8686 - val_loss: 0.4934 - val_acc: 0.8760\n",
      "Epoch 30/100\n",
      "22500/22500 [==============================] - 4s 175us/step - loss: 0.5152 - acc: 0.8675 - val_loss: 0.4938 - val_acc: 0.8724\n",
      "Epoch 31/100\n",
      "22500/22500 [==============================] - 4s 182us/step - loss: 0.5157 - acc: 0.8715 - val_loss: 0.4907 - val_acc: 0.8812\n",
      "Epoch 32/100\n",
      "22500/22500 [==============================] - 4s 177us/step - loss: 0.5147 - acc: 0.8691 - val_loss: 0.4862 - val_acc: 0.8760\n",
      "Epoch 33/100\n",
      "22500/22500 [==============================] - 4s 180us/step - loss: 0.5076 - acc: 0.8726 - val_loss: 0.4800 - val_acc: 0.8820\n",
      "Epoch 34/100\n",
      "22500/22500 [==============================] - 4s 178us/step - loss: 0.5140 - acc: 0.8677 - val_loss: 0.4869 - val_acc: 0.8744\n",
      "Epoch 35/100\n",
      "22500/22500 [==============================] - 4s 178us/step - loss: 0.5115 - acc: 0.8694 - val_loss: 0.4746 - val_acc: 0.8856\n",
      "Epoch 36/100\n",
      "22500/22500 [==============================] - 4s 177us/step - loss: 0.4996 - acc: 0.8714 - val_loss: 0.4756 - val_acc: 0.8812\n",
      "Epoch 37/100\n",
      "22500/22500 [==============================] - 4s 182us/step - loss: 0.4997 - acc: 0.8702 - val_loss: 0.4813 - val_acc: 0.8740\n",
      "Epoch 38/100\n",
      "22500/22500 [==============================] - 4s 176us/step - loss: 0.5031 - acc: 0.8673 - val_loss: 0.4896 - val_acc: 0.8804\n",
      "Epoch 39/100\n",
      "22500/22500 [==============================] - 4s 181us/step - loss: 0.5088 - acc: 0.8686 - val_loss: 0.4777 - val_acc: 0.8768\n",
      "Epoch 40/100\n",
      "22500/22500 [==============================] - 4s 177us/step - loss: 0.4995 - acc: 0.8724 - val_loss: 0.4729 - val_acc: 0.8776\n",
      "Epoch 41/100\n",
      "22500/22500 [==============================] - 4s 181us/step - loss: 0.4952 - acc: 0.8739 - val_loss: 0.4736 - val_acc: 0.8812\n",
      "Epoch 42/100\n",
      "22500/22500 [==============================] - 4s 182us/step - loss: 0.4959 - acc: 0.8731 - val_loss: 0.4741 - val_acc: 0.8872\n",
      "Epoch 43/100\n",
      "22500/22500 [==============================] - 4s 182us/step - loss: 0.4963 - acc: 0.8746 - val_loss: 0.4774 - val_acc: 0.8764\n",
      "Epoch 44/100\n",
      "22500/22500 [==============================] - 4s 190us/step - loss: 0.5043 - acc: 0.8684 - val_loss: 0.4709 - val_acc: 0.8808\n",
      "Epoch 45/100\n",
      "22500/22500 [==============================] - 4s 181us/step - loss: 0.4918 - acc: 0.8732 - val_loss: 0.4704 - val_acc: 0.8816\n",
      "Epoch 46/100\n",
      "22500/22500 [==============================] - 4s 181us/step - loss: 0.4836 - acc: 0.8748 - val_loss: 0.4705 - val_acc: 0.8800\n",
      "Epoch 47/100\n",
      "22500/22500 [==============================] - 4s 182us/step - loss: 0.4864 - acc: 0.8750 - val_loss: 0.4737 - val_acc: 0.8768\n",
      "Epoch 48/100\n",
      "22500/22500 [==============================] - 4s 181us/step - loss: 0.4903 - acc: 0.8739 - val_loss: 0.4718 - val_acc: 0.8816\n",
      "Epoch 49/100\n",
      "22500/22500 [==============================] - 4s 178us/step - loss: 0.4951 - acc: 0.8708 - val_loss: 0.4744 - val_acc: 0.8784\n",
      "Epoch 50/100\n",
      "22500/22500 [==============================] - 4s 185us/step - loss: 0.4831 - acc: 0.8800 - val_loss: 0.4732 - val_acc: 0.8832\n",
      "Epoch 51/100\n",
      "22500/22500 [==============================] - 4s 183us/step - loss: 0.4836 - acc: 0.8756 - val_loss: 0.4753 - val_acc: 0.8752\n",
      "Epoch 52/100\n",
      "22500/22500 [==============================] - 4s 186us/step - loss: 0.4907 - acc: 0.8740 - val_loss: 0.4695 - val_acc: 0.8856\n",
      "Epoch 53/100\n",
      "22500/22500 [==============================] - 4s 179us/step - loss: 0.4867 - acc: 0.8764 - val_loss: 0.4735 - val_acc: 0.8832\n",
      "Epoch 54/100\n",
      "22500/22500 [==============================] - 4s 180us/step - loss: 0.4856 - acc: 0.8736 - val_loss: 0.4773 - val_acc: 0.8776\n",
      "Epoch 55/100\n",
      "22500/22500 [==============================] - 4s 180us/step - loss: 0.4859 - acc: 0.8768 - val_loss: 0.4720 - val_acc: 0.8752\n",
      "Epoch 56/100\n",
      "22500/22500 [==============================] - 4s 186us/step - loss: 0.4919 - acc: 0.8692 - val_loss: 0.4764 - val_acc: 0.8812\n",
      "Epoch 57/100\n",
      "22500/22500 [==============================] - 4s 186us/step - loss: 0.4811 - acc: 0.8754 - val_loss: 0.4792 - val_acc: 0.8792\n",
      "Epoch 58/100\n",
      "22500/22500 [==============================] - 4s 177us/step - loss: 0.4869 - acc: 0.8748 - val_loss: 0.4713 - val_acc: 0.8820\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22500/22500 [==============================] - 4s 175us/step - loss: 0.4805 - acc: 0.8777 - val_loss: 0.4855 - val_acc: 0.8624\n",
      "Epoch 60/100\n",
      "22500/22500 [==============================] - 4s 180us/step - loss: 0.4798 - acc: 0.8752 - val_loss: 0.4699 - val_acc: 0.8820\n",
      "Epoch 61/100\n",
      "22500/22500 [==============================] - 4s 172us/step - loss: 0.4816 - acc: 0.8772 - val_loss: 0.4815 - val_acc: 0.8840\n",
      "Epoch 62/100\n",
      "22500/22500 [==============================] - 4s 179us/step - loss: 0.4724 - acc: 0.8806 - val_loss: 0.4802 - val_acc: 0.8812\n",
      "Epoch 63/100\n",
      "22500/22500 [==============================] - 4s 181us/step - loss: 0.4857 - acc: 0.8760 - val_loss: 0.4776 - val_acc: 0.8712\n",
      "Epoch 64/100\n",
      "22500/22500 [==============================] - 4s 180us/step - loss: 0.4763 - acc: 0.8789 - val_loss: 0.4757 - val_acc: 0.8760\n",
      "Epoch 65/100\n",
      "22500/22500 [==============================] - 4s 170us/step - loss: 0.4776 - acc: 0.8764 - val_loss: 0.4792 - val_acc: 0.8704\n",
      "Epoch 66/100\n",
      "22500/22500 [==============================] - 4s 179us/step - loss: 0.4765 - acc: 0.8795 - val_loss: 0.4714 - val_acc: 0.8844\n",
      "Epoch 67/100\n",
      "22500/22500 [==============================] - 4s 186us/step - loss: 0.4803 - acc: 0.8760 - val_loss: 0.4711 - val_acc: 0.8832\n",
      "Epoch 68/100\n",
      "22500/22500 [==============================] - 4s 186us/step - loss: 0.4738 - acc: 0.8785 - val_loss: 0.4817 - val_acc: 0.8800\n",
      "Epoch 69/100\n",
      "22500/22500 [==============================] - 4s 180us/step - loss: 0.4734 - acc: 0.8809 - val_loss: 0.4758 - val_acc: 0.8784\n",
      "Epoch 70/100\n",
      "22500/22500 [==============================] - 4s 184us/step - loss: 0.4772 - acc: 0.8780 - val_loss: 0.4863 - val_acc: 0.8744\n",
      "Epoch 71/100\n",
      "22500/22500 [==============================] - 4s 176us/step - loss: 0.4829 - acc: 0.8778 - val_loss: 0.4743 - val_acc: 0.8812\n",
      "Epoch 72/100\n",
      "22500/22500 [==============================] - 4s 194us/step - loss: 0.4811 - acc: 0.8760 - val_loss: 0.4742 - val_acc: 0.8788\n",
      "Epoch 73/100\n",
      "22500/22500 [==============================] - 5s 201us/step - loss: 0.4786 - acc: 0.8764 - val_loss: 0.4889 - val_acc: 0.8824\n",
      "Epoch 74/100\n",
      "22500/22500 [==============================] - 5s 209us/step - loss: 0.4682 - acc: 0.8832 - val_loss: 0.4703 - val_acc: 0.8784\n",
      "Epoch 75/100\n",
      "22500/22500 [==============================] - 4s 197us/step - loss: 0.4682 - acc: 0.8822 - val_loss: 0.4709 - val_acc: 0.8764\n",
      "Epoch 76/100\n",
      "22500/22500 [==============================] - 5s 202us/step - loss: 0.4740 - acc: 0.8797 - val_loss: 0.4895 - val_acc: 0.8716\n",
      "Epoch 77/100\n",
      "22500/22500 [==============================] - 5s 209us/step - loss: 0.4828 - acc: 0.8776 - val_loss: 0.4790 - val_acc: 0.8784\n",
      "Epoch 78/100\n",
      "22500/22500 [==============================] - 4s 189us/step - loss: 0.4726 - acc: 0.8808 - val_loss: 0.4796 - val_acc: 0.8740\n",
      "Epoch 79/100\n",
      "22500/22500 [==============================] - 4s 181us/step - loss: 0.4697 - acc: 0.8812 - val_loss: 0.4853 - val_acc: 0.8812\n",
      "Epoch 80/100\n",
      "22500/22500 [==============================] - 4s 179us/step - loss: 0.4698 - acc: 0.8815 - val_loss: 0.4850 - val_acc: 0.8792\n",
      "Epoch 81/100\n",
      "22500/22500 [==============================] - 4s 172us/step - loss: 0.4658 - acc: 0.8829 - val_loss: 0.4792 - val_acc: 0.8784\n",
      "Epoch 82/100\n",
      "22500/22500 [==============================] - 4s 184us/step - loss: 0.4661 - acc: 0.8843 - val_loss: 0.4730 - val_acc: 0.8756\n",
      "Epoch 83/100\n",
      "22500/22500 [==============================] - 4s 188us/step - loss: 0.4734 - acc: 0.8819 - val_loss: 0.4744 - val_acc: 0.8760\n",
      "Epoch 84/100\n",
      "22500/22500 [==============================] - 4s 172us/step - loss: 0.4711 - acc: 0.8810 - val_loss: 0.4739 - val_acc: 0.8776\n",
      "Epoch 85/100\n",
      "22500/22500 [==============================] - 4s 200us/step - loss: 0.4650 - acc: 0.8819 - val_loss: 0.4891 - val_acc: 0.8824\n",
      "Epoch 86/100\n",
      "22500/22500 [==============================] - 4s 178us/step - loss: 0.4714 - acc: 0.8837 - val_loss: 0.4812 - val_acc: 0.8820\n",
      "Epoch 87/100\n",
      "22500/22500 [==============================] - 5s 210us/step - loss: 0.4711 - acc: 0.8817 - val_loss: 0.4773 - val_acc: 0.8772\n",
      "Epoch 88/100\n",
      "22500/22500 [==============================] - 4s 180us/step - loss: 0.4667 - acc: 0.8810 - val_loss: 0.4756 - val_acc: 0.8788\n",
      "Epoch 89/100\n",
      "22500/22500 [==============================] - 4s 176us/step - loss: 0.4576 - acc: 0.8868 - val_loss: 0.4797 - val_acc: 0.8788\n",
      "Epoch 90/100\n",
      "22500/22500 [==============================] - 4s 182us/step - loss: 0.4580 - acc: 0.8877 - val_loss: 0.4845 - val_acc: 0.8804\n",
      "Epoch 91/100\n",
      "22500/22500 [==============================] - 4s 177us/step - loss: 0.4667 - acc: 0.8839 - val_loss: 0.4991 - val_acc: 0.8792\n",
      "Epoch 92/100\n",
      "22500/22500 [==============================] - 4s 185us/step - loss: 0.4722 - acc: 0.8803 - val_loss: 0.4859 - val_acc: 0.8744\n",
      "Epoch 93/100\n",
      "22500/22500 [==============================] - 4s 178us/step - loss: 0.4712 - acc: 0.8830 - val_loss: 0.4814 - val_acc: 0.8772\n",
      "Epoch 94/100\n",
      "22500/22500 [==============================] - 4s 181us/step - loss: 0.4661 - acc: 0.8841 - val_loss: 0.4724 - val_acc: 0.8844\n",
      "Epoch 95/100\n",
      "22500/22500 [==============================] - 4s 182us/step - loss: 0.4697 - acc: 0.8815 - val_loss: 0.4823 - val_acc: 0.8780\n",
      "Epoch 96/100\n",
      "22500/22500 [==============================] - 4s 180us/step - loss: 0.4657 - acc: 0.8865 - val_loss: 0.4771 - val_acc: 0.8812\n",
      "Epoch 97/100\n",
      "22500/22500 [==============================] - 4s 174us/step - loss: 0.4594 - acc: 0.8896 - val_loss: 0.4816 - val_acc: 0.8740\n",
      "Epoch 98/100\n",
      "22500/22500 [==============================] - 4s 189us/step - loss: 0.4643 - acc: 0.8844 - val_loss: 0.4844 - val_acc: 0.8780\n",
      "Epoch 99/100\n",
      "22500/22500 [==============================] - 4s 174us/step - loss: 0.4573 - acc: 0.8919 - val_loss: 0.4905 - val_acc: 0.8796\n",
      "Epoch 100/100\n",
      "22500/22500 [==============================] - 4s 171us/step - loss: 0.4676 - acc: 0.8837 - val_loss: 0.5098 - val_acc: 0.8808\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb39a7fbe0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train2, y_train2, epochs=100, batch_size=512, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come puoi vedere, al termine di ogni epoca il modello viene valutato anche sul set di validazione, calcolando le metriche da noi indicate, in questo caso binary crossentropy e accuracy.\n",
    "<br><br>\n",
    "Infine, per valutare la capacità predittiva effettiva del modello, dobbiamo testarlo sul set di test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 3s 134us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5102350357437134, 0.87224]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opzione 2: Estrarre automaticamente un set di validazione\n",
    "La seconda opzione consiste nel lasciare che Keras estragga automaticamente un set di validazione dal set di addestramento, specificandone la dimensione. Creiamo nuovamente il modello."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "model.compile(optimizer='adamax', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adesso passiamo al metodo <span style=\"font-family: Monaco\">fit</span>. il parametro <span style=\"font-family: Monaco\">validation_split</span>, indicando all'interno la frazione del set di addestramento da utilizzare come set di validazione, utilizziamo il 10% specificando 0.1, quindi dato questo conterrà sempre 2500 esempi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22500 samples, validate on 2500 samples\n",
      "Epoch 1/100\n",
      "22500/22500 [==============================] - 5s 200us/step - loss: 13.5702 - acc: 0.5478 - val_loss: 1.3525 - val_acc: 0.7284\n",
      "Epoch 2/100\n",
      "22500/22500 [==============================] - 4s 179us/step - loss: 0.9302 - acc: 0.7036 - val_loss: 0.7166 - val_acc: 0.8496\n",
      "Epoch 3/100\n",
      "22500/22500 [==============================] - 3s 146us/step - loss: 0.7409 - acc: 0.7820 - val_loss: 0.6388 - val_acc: 0.8584\n",
      "Epoch 4/100\n",
      "22500/22500 [==============================] - 4s 184us/step - loss: 0.7081 - acc: 0.8136 - val_loss: 0.6198 - val_acc: 0.8656\n",
      "Epoch 5/100\n",
      "22500/22500 [==============================] - 3s 153us/step - loss: 0.7035 - acc: 0.8170 - val_loss: 0.5876 - val_acc: 0.8604\n",
      "Epoch 6/100\n",
      "22500/22500 [==============================] - 4s 163us/step - loss: 0.6485 - acc: 0.8355 - val_loss: 0.5777 - val_acc: 0.8716\n",
      "Epoch 7/100\n",
      "22500/22500 [==============================] - 4s 166us/step - loss: 0.6466 - acc: 0.8408 - val_loss: 0.6540 - val_acc: 0.8180\n",
      "Epoch 8/100\n",
      "22500/22500 [==============================] - 4s 166us/step - loss: 0.6356 - acc: 0.8368 - val_loss: 0.5623 - val_acc: 0.8688\n",
      "Epoch 9/100\n",
      "22500/22500 [==============================] - 4s 159us/step - loss: 0.6096 - acc: 0.8467 - val_loss: 0.5683 - val_acc: 0.8528\n",
      "Epoch 10/100\n",
      "22500/22500 [==============================] - 4s 163us/step - loss: 0.6182 - acc: 0.8432 - val_loss: 0.5342 - val_acc: 0.8768\n",
      "Epoch 11/100\n",
      "22500/22500 [==============================] - 4s 172us/step - loss: 0.5904 - acc: 0.8501 - val_loss: 0.5256 - val_acc: 0.8792\n",
      "Epoch 12/100\n",
      "22500/22500 [==============================] - 4s 180us/step - loss: 0.5858 - acc: 0.8526 - val_loss: 0.5180 - val_acc: 0.8744\n",
      "Epoch 13/100\n",
      "22500/22500 [==============================] - 4s 164us/step - loss: 0.5725 - acc: 0.8554 - val_loss: 0.5044 - val_acc: 0.8788\n",
      "Epoch 14/100\n",
      "22500/22500 [==============================] - 4s 185us/step - loss: 0.5788 - acc: 0.8500 - val_loss: 0.5374 - val_acc: 0.8616\n",
      "Epoch 15/100\n",
      "22500/22500 [==============================] - 4s 195us/step - loss: 0.5739 - acc: 0.8552 - val_loss: 0.5412 - val_acc: 0.8588\n",
      "Epoch 16/100\n",
      "22500/22500 [==============================] - 5s 207us/step - loss: 0.5752 - acc: 0.8511 - val_loss: 0.4974 - val_acc: 0.8800\n",
      "Epoch 17/100\n",
      "22500/22500 [==============================] - 5s 212us/step - loss: 0.5516 - acc: 0.8604 - val_loss: 0.4925 - val_acc: 0.8764\n",
      "Epoch 18/100\n",
      "22500/22500 [==============================] - 4s 192us/step - loss: 0.5488 - acc: 0.8618 - val_loss: 0.4968 - val_acc: 0.8752\n",
      "Epoch 19/100\n",
      "22500/22500 [==============================] - 5s 222us/step - loss: 0.5527 - acc: 0.8602 - val_loss: 0.5137 - val_acc: 0.8684\n",
      "Epoch 20/100\n",
      "22500/22500 [==============================] - 4s 196us/step - loss: 0.5541 - acc: 0.8590 - val_loss: 0.4926 - val_acc: 0.8776\n",
      "Epoch 21/100\n",
      "22500/22500 [==============================] - 4s 190us/step - loss: 0.5396 - acc: 0.8646 - val_loss: 0.4867 - val_acc: 0.8796\n",
      "Epoch 22/100\n",
      "22500/22500 [==============================] - 5s 205us/step - loss: 0.5428 - acc: 0.8631 - val_loss: 0.4846 - val_acc: 0.8860\n",
      "Epoch 23/100\n",
      "22500/22500 [==============================] - 4s 184us/step - loss: 0.5409 - acc: 0.8642 - val_loss: 0.4997 - val_acc: 0.8736\n",
      "Epoch 24/100\n",
      "22500/22500 [==============================] - 5s 230us/step - loss: 0.5457 - acc: 0.8594 - val_loss: 0.4872 - val_acc: 0.8784\n",
      "Epoch 25/100\n",
      "22500/22500 [==============================] - 4s 183us/step - loss: 0.5369 - acc: 0.8616 - val_loss: 0.4965 - val_acc: 0.8684\n",
      "Epoch 26/100\n",
      "22500/22500 [==============================] - 4s 166us/step - loss: 0.5289 - acc: 0.8676 - val_loss: 0.4933 - val_acc: 0.8712\n",
      "Epoch 27/100\n",
      "22500/22500 [==============================] - 4s 164us/step - loss: 0.5274 - acc: 0.8660 - val_loss: 0.4778 - val_acc: 0.8760\n",
      "Epoch 28/100\n",
      "22500/22500 [==============================] - 4s 159us/step - loss: 0.5283 - acc: 0.8667 - val_loss: 0.4854 - val_acc: 0.8752\n",
      "Epoch 29/100\n",
      "22500/22500 [==============================] - 4s 159us/step - loss: 0.5260 - acc: 0.8683 - val_loss: 0.4848 - val_acc: 0.8768\n",
      "Epoch 30/100\n",
      "22500/22500 [==============================] - 4s 164us/step - loss: 0.5310 - acc: 0.8619 - val_loss: 0.4903 - val_acc: 0.8768\n",
      "Epoch 31/100\n",
      "22500/22500 [==============================] - 4s 170us/step - loss: 0.5248 - acc: 0.8658 - val_loss: 0.4829 - val_acc: 0.8776\n",
      "Epoch 32/100\n",
      "22500/22500 [==============================] - 4s 162us/step - loss: 0.5207 - acc: 0.8694 - val_loss: 0.4741 - val_acc: 0.8756\n",
      "Epoch 33/100\n",
      "22500/22500 [==============================] - 4s 165us/step - loss: 0.5201 - acc: 0.8717 - val_loss: 0.4797 - val_acc: 0.8784\n",
      "Epoch 34/100\n",
      "22500/22500 [==============================] - 4s 161us/step - loss: 0.5185 - acc: 0.8681 - val_loss: 0.4765 - val_acc: 0.8800\n",
      "Epoch 35/100\n",
      "22500/22500 [==============================] - 4s 176us/step - loss: 0.5169 - acc: 0.8721 - val_loss: 0.4748 - val_acc: 0.8792\n",
      "Epoch 36/100\n",
      "22500/22500 [==============================] - 4s 161us/step - loss: 0.5187 - acc: 0.8672 - val_loss: 0.5080 - val_acc: 0.8604\n",
      "Epoch 37/100\n",
      "22500/22500 [==============================] - 4s 162us/step - loss: 0.5223 - acc: 0.8670 - val_loss: 0.4776 - val_acc: 0.8768\n",
      "Epoch 38/100\n",
      "22500/22500 [==============================] - 4s 161us/step - loss: 0.5166 - acc: 0.8680 - val_loss: 0.4805 - val_acc: 0.8836\n",
      "Epoch 39/100\n",
      "22500/22500 [==============================] - 4s 162us/step - loss: 0.5197 - acc: 0.8706 - val_loss: 0.4781 - val_acc: 0.8788\n",
      "Epoch 40/100\n",
      "22500/22500 [==============================] - 4s 160us/step - loss: 0.5201 - acc: 0.8712 - val_loss: 0.4744 - val_acc: 0.8768\n",
      "Epoch 41/100\n",
      "22500/22500 [==============================] - 4s 162us/step - loss: 0.5094 - acc: 0.8736 - val_loss: 0.4707 - val_acc: 0.8848\n",
      "Epoch 42/100\n",
      "22500/22500 [==============================] - 4s 164us/step - loss: 0.5102 - acc: 0.8698 - val_loss: 0.4798 - val_acc: 0.8764\n",
      "Epoch 43/100\n",
      "22500/22500 [==============================] - 4s 168us/step - loss: 0.5123 - acc: 0.8720 - val_loss: 0.4777 - val_acc: 0.8780\n",
      "Epoch 44/100\n",
      "22500/22500 [==============================] - 4s 167us/step - loss: 0.5165 - acc: 0.8704 - val_loss: 0.4802 - val_acc: 0.8796\n",
      "Epoch 45/100\n",
      "22500/22500 [==============================] - 6s 284us/step - loss: 0.5051 - acc: 0.8744 - val_loss: 0.4782 - val_acc: 0.8768\n",
      "Epoch 46/100\n",
      "22500/22500 [==============================] - 4s 157us/step - loss: 0.5056 - acc: 0.8757 - val_loss: 0.4791 - val_acc: 0.8768\n",
      "Epoch 47/100\n",
      "22500/22500 [==============================] - 3s 155us/step - loss: 0.5042 - acc: 0.8742 - val_loss: 0.4718 - val_acc: 0.8872\n",
      "Epoch 48/100\n",
      "22500/22500 [==============================] - 4s 158us/step - loss: 0.5039 - acc: 0.8741 - val_loss: 0.4766 - val_acc: 0.8776\n",
      "Epoch 49/100\n",
      "22500/22500 [==============================] - 5s 229us/step - loss: 0.5049 - acc: 0.8764 - val_loss: 0.4819 - val_acc: 0.8768\n",
      "Epoch 50/100\n",
      "22500/22500 [==============================] - 4s 187us/step - loss: 0.5120 - acc: 0.8721 - val_loss: 0.4748 - val_acc: 0.8800\n",
      "Epoch 51/100\n",
      "22500/22500 [==============================] - 4s 176us/step - loss: 0.4988 - acc: 0.8776 - val_loss: 0.4716 - val_acc: 0.8820\n",
      "Epoch 52/100\n",
      "22500/22500 [==============================] - 5s 232us/step - loss: 0.4905 - acc: 0.8809 - val_loss: 0.4736 - val_acc: 0.8760\n",
      "Epoch 53/100\n",
      "22500/22500 [==============================] - 6s 287us/step - loss: 0.4986 - acc: 0.8782 - val_loss: 0.4784 - val_acc: 0.8736\n",
      "Epoch 54/100\n",
      "22500/22500 [==============================] - 4s 166us/step - loss: 0.5030 - acc: 0.8735 - val_loss: 0.4700 - val_acc: 0.8848\n",
      "Epoch 55/100\n",
      "22500/22500 [==============================] - 4s 178us/step - loss: 0.4937 - acc: 0.8801 - val_loss: 0.4706 - val_acc: 0.8788\n",
      "Epoch 56/100\n",
      "22500/22500 [==============================] - 5s 206us/step - loss: 0.5055 - acc: 0.8740 - val_loss: 0.4715 - val_acc: 0.8788\n",
      "Epoch 57/100\n",
      "22500/22500 [==============================] - 11s 474us/step - loss: 0.4948 - acc: 0.8762 - val_loss: 0.4677 - val_acc: 0.8780\n",
      "Epoch 58/100\n",
      "22500/22500 [==============================] - 4s 171us/step - loss: 0.4962 - acc: 0.8769 - val_loss: 0.4689 - val_acc: 0.8768\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22500/22500 [==============================] - 4s 168us/step - loss: 0.4953 - acc: 0.8774 - val_loss: 0.4683 - val_acc: 0.8744\n",
      "Epoch 60/100\n",
      "22500/22500 [==============================] - 4s 170us/step - loss: 0.4837 - acc: 0.8804 - val_loss: 0.4637 - val_acc: 0.8824\n",
      "Epoch 61/100\n",
      "22500/22500 [==============================] - 7s 303us/step - loss: 0.4891 - acc: 0.8778 - val_loss: 0.4722 - val_acc: 0.8752\n",
      "Epoch 62/100\n",
      "22500/22500 [==============================] - 9s 386us/step - loss: 0.4919 - acc: 0.8788 - val_loss: 0.4910 - val_acc: 0.8708\n",
      "Epoch 63/100\n",
      "22500/22500 [==============================] - 4s 194us/step - loss: 0.4869 - acc: 0.8816 - val_loss: 0.4635 - val_acc: 0.8804\n",
      "Epoch 64/100\n",
      "22500/22500 [==============================] - 4s 200us/step - loss: 0.4871 - acc: 0.8796 - val_loss: 0.4706 - val_acc: 0.8824\n",
      "Epoch 65/100\n",
      "22500/22500 [==============================] - 9s 403us/step - loss: 0.4878 - acc: 0.8819 - val_loss: 0.4725 - val_acc: 0.8820\n",
      "Epoch 66/100\n",
      "22500/22500 [==============================] - 5s 217us/step - loss: 0.4892 - acc: 0.8804 - val_loss: 0.4704 - val_acc: 0.8760\n",
      "Epoch 67/100\n",
      "22500/22500 [==============================] - 8s 340us/step - loss: 0.4905 - acc: 0.8793 - val_loss: 0.4618 - val_acc: 0.8796\n",
      "Epoch 68/100\n",
      "22500/22500 [==============================] - 7s 289us/step - loss: 0.4894 - acc: 0.8780 - val_loss: 0.4685 - val_acc: 0.8808\n",
      "Epoch 69/100\n",
      "22500/22500 [==============================] - 4s 165us/step - loss: 0.4879 - acc: 0.8802 - val_loss: 0.4690 - val_acc: 0.8796\n",
      "Epoch 70/100\n",
      "22500/22500 [==============================] - 7s 309us/step - loss: 0.4847 - acc: 0.8811 - val_loss: 0.4698 - val_acc: 0.8796\n",
      "Epoch 71/100\n",
      "22500/22500 [==============================] - 5s 225us/step - loss: 0.4841 - acc: 0.8806 - val_loss: 0.4790 - val_acc: 0.8768\n",
      "Epoch 72/100\n",
      "22500/22500 [==============================] - 9s 392us/step - loss: 0.4843 - acc: 0.8811 - val_loss: 0.4670 - val_acc: 0.8816\n",
      "Epoch 73/100\n",
      "22500/22500 [==============================] - 4s 167us/step - loss: 0.4854 - acc: 0.8796 - val_loss: 0.4709 - val_acc: 0.8768\n",
      "Epoch 74/100\n",
      "22500/22500 [==============================] - 7s 313us/step - loss: 0.4814 - acc: 0.8827 - val_loss: 0.4650 - val_acc: 0.8804\n",
      "Epoch 75/100\n",
      "22500/22500 [==============================] - 7s 325us/step - loss: 0.4766 - acc: 0.8844 - val_loss: 0.4699 - val_acc: 0.8784\n",
      "Epoch 76/100\n",
      "22500/22500 [==============================] - 6s 250us/step - loss: 0.4766 - acc: 0.8815 - val_loss: 0.4699 - val_acc: 0.8800\n",
      "Epoch 77/100\n",
      "22500/22500 [==============================] - 5s 240us/step - loss: 0.4818 - acc: 0.8834 - val_loss: 0.4715 - val_acc: 0.8776\n",
      "Epoch 78/100\n",
      "22500/22500 [==============================] - 10s 451us/step - loss: 0.4783 - acc: 0.8831 - val_loss: 0.4677 - val_acc: 0.8868\n",
      "Epoch 79/100\n",
      "22500/22500 [==============================] - 4s 188us/step - loss: 0.4808 - acc: 0.8844 - val_loss: 0.4753 - val_acc: 0.8764\n",
      "Epoch 80/100\n",
      "22500/22500 [==============================] - 11s 486us/step - loss: 0.4898 - acc: 0.8769 - val_loss: 0.4695 - val_acc: 0.8840\n",
      "Epoch 81/100\n",
      "22500/22500 [==============================] - 4s 169us/step - loss: 0.4783 - acc: 0.8839 - val_loss: 0.4644 - val_acc: 0.8816\n",
      "Epoch 82/100\n",
      "22500/22500 [==============================] - 4s 174us/step - loss: 0.4632 - acc: 0.8895 - val_loss: 0.4625 - val_acc: 0.8804\n",
      "Epoch 83/100\n",
      "22500/22500 [==============================] - 10s 429us/step - loss: 0.4704 - acc: 0.8873 - val_loss: 0.4684 - val_acc: 0.8788\n",
      "Epoch 84/100\n",
      "22500/22500 [==============================] - 4s 192us/step - loss: 0.4773 - acc: 0.8824 - val_loss: 0.4663 - val_acc: 0.8832\n",
      "Epoch 85/100\n",
      "22500/22500 [==============================] - 10s 445us/step - loss: 0.4759 - acc: 0.8835 - val_loss: 0.4620 - val_acc: 0.8808\n",
      "Epoch 86/100\n",
      "22500/22500 [==============================] - 4s 177us/step - loss: 0.4729 - acc: 0.8846 - val_loss: 0.4644 - val_acc: 0.8776\n",
      "Epoch 87/100\n",
      "22500/22500 [==============================] - 12s 516us/step - loss: 0.4748 - acc: 0.8837 - val_loss: 0.4692 - val_acc: 0.8768\n",
      "Epoch 88/100\n",
      "22500/22500 [==============================] - 7s 324us/step - loss: 0.4744 - acc: 0.8856 - val_loss: 0.4671 - val_acc: 0.8804\n",
      "Epoch 89/100\n",
      "22500/22500 [==============================] - 9s 418us/step - loss: 0.4775 - acc: 0.8856 - val_loss: 0.4634 - val_acc: 0.8832\n",
      "Epoch 90/100\n",
      "22500/22500 [==============================] - 9s 395us/step - loss: 0.4687 - acc: 0.8872 - val_loss: 0.4703 - val_acc: 0.8736\n",
      "Epoch 91/100\n",
      "22500/22500 [==============================] - 7s 296us/step - loss: 0.4678 - acc: 0.8887 - val_loss: 0.4694 - val_acc: 0.8780\n",
      "Epoch 92/100\n",
      "22500/22500 [==============================] - 7s 307us/step - loss: 0.4741 - acc: 0.8836 - val_loss: 0.4708 - val_acc: 0.8800\n",
      "Epoch 93/100\n",
      "22500/22500 [==============================] - 5s 214us/step - loss: 0.4733 - acc: 0.8861 - val_loss: 0.4633 - val_acc: 0.8868\n",
      "Epoch 94/100\n",
      "22500/22500 [==============================] - 8s 368us/step - loss: 0.4818 - acc: 0.8828 - val_loss: 0.4688 - val_acc: 0.8812\n",
      "Epoch 95/100\n",
      "22500/22500 [==============================] - 4s 164us/step - loss: 0.4691 - acc: 0.8886 - val_loss: 0.4665 - val_acc: 0.8796\n",
      "Epoch 96/100\n",
      "22500/22500 [==============================] - 6s 286us/step - loss: 0.4678 - acc: 0.8900 - val_loss: 0.4686 - val_acc: 0.8800\n",
      "Epoch 97/100\n",
      "22500/22500 [==============================] - 4s 164us/step - loss: 0.4663 - acc: 0.8876 - val_loss: 0.4757 - val_acc: 0.8784\n",
      "Epoch 98/100\n",
      "22500/22500 [==============================] - 7s 312us/step - loss: 0.4673 - acc: 0.8871 - val_loss: 0.4712 - val_acc: 0.8724\n",
      "Epoch 99/100\n",
      "22500/22500 [==============================] - 6s 255us/step - loss: 0.4781 - acc: 0.8842 - val_loss: 0.4718 - val_acc: 0.8768\n",
      "Epoch 100/100\n",
      "22500/22500 [==============================] - 9s 390us/step - loss: 0.4686 - acc: 0.8887 - val_loss: 0.4806 - val_acc: 0.8700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb296a0320>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100, batch_size=512, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E testiamo di nuovo sul set di test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 8s 329us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.47609062995910645, 0.86992]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
