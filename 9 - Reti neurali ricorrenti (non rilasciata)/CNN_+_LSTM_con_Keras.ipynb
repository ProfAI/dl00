{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN + LSTM con Keras.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ProfAI/dl00/blob/master/9%20-%20Reti%20neurali%20ricorrenti%20(non%20rilasciata)/CNN_%2B_LSTM_con_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "SDGEK3yNerdL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# CNN + LSTM con Keras\n",
        "\n",
        "In questo notebook proveremo a creare una rete neurale che combina uno strato convoluzionale con uno strato ricorrente per classificare le recensioni del IMDB Movie Reviews Dataset.\n",
        "<br><br>\n",
        "Importiamo i moduli che ci serviranno."
      ]
    },
    {
      "metadata": {
        "id": "Jz5zRrEteY_S",
        "colab_type": "code",
        "outputId": "5f3bdf9f-a261-4c7d-9411-502e11b8d53c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.datasets import imdb \n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "uadT-PS2eyph",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Caricamento e preprocessing del dataset\n",
        "Carichiamo il dataset con Keras limitandolo alle 10.000 parole più comuni, poi tronchiamo/espandiamo le sequenze a 500 elementi con la funzione pad_sequences."
      ]
    },
    {
      "metadata": {
        "id": "OYrwWo6iew4e",
        "colab_type": "code",
        "outputId": "86e19ff7-22a7-42da-eda7-5d1e07805262",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "num_words = 10000\n",
        "maxlen = 500\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=num_words)\n",
        "\n",
        "X_train = pad_sequences(X_train, maxlen = maxlen)\n",
        "X_test = pad_sequences(X_test, maxlen = maxlen)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "U15rdAaW_gZp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Creazione del modello"
      ]
    },
    {
      "metadata": {
        "id": "ZQJ1eW85_VMd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Modello1: Rete convoluzionale"
      ]
    },
    {
      "metadata": {
        "id": "dI-QTYrJ9yGH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "outputId": "432c479c-9663-4bf4-fd3b-119f0eea0900"
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Embedding, LSTM, Flatten\n",
        "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(num_words, 50, input_length=500))\n",
        "model.add(Conv1D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 500, 50)           500000    \n",
            "_________________________________________________________________\n",
            "conv1d_5 (Conv1D)            (None, 500, 32)           4832      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_5 (MaxPooling1 (None, 250, 32)           0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 8000)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 8001      \n",
            "=================================================================\n",
            "Total params: 512,833\n",
            "Trainable params: 512,833\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "s8nnGu_Y93DN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "ddb313ef-b4d9-46fc-a044-fb6d11213ba0"
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, batch_size=512, validation_split=0.2, epochs=5)\n",
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 20000 samples, validate on 5000 samples\n",
            "Epoch 1/5\n",
            "20000/20000 [==============================] - 23s 1ms/step - loss: 0.6667 - acc: 0.6021 - val_loss: 0.6008 - val_acc: 0.6446\n",
            "Epoch 2/5\n",
            "20000/20000 [==============================] - 23s 1ms/step - loss: 0.4301 - acc: 0.8371 - val_loss: 0.4048 - val_acc: 0.8112\n",
            "Epoch 3/5\n",
            "20000/20000 [==============================] - 23s 1ms/step - loss: 0.2762 - acc: 0.8968 - val_loss: 0.3602 - val_acc: 0.8406\n",
            "Epoch 4/5\n",
            "20000/20000 [==============================] - 23s 1ms/step - loss: 0.2162 - acc: 0.9177 - val_loss: 0.2894 - val_acc: 0.8824\n",
            "Epoch 5/5\n",
            "20000/20000 [==============================] - 23s 1ms/step - loss: 0.1833 - acc: 0.9308 - val_loss: 0.3157 - val_acc: 0.8734\n",
            "25000/25000 [==============================] - 12s 470us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3152529398679733, 0.87084]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "jLb7hLxk43F3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Modello 2: Da ricorrente a convoluzionale"
      ]
    },
    {
      "metadata": {
        "id": "F5mxg9MI46YQ",
        "colab_type": "code",
        "outputId": "82fb4a19-e583-42d3-f773-18ac3a6619d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Embedding, LSTM, Flatten\n",
        "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(num_words, 50, input_length=500))\n",
        "model.add(LSTM(32, dropout=0.4, return_sequences=True))\n",
        "model.add(Conv1D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 500, 50)           500000    \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 500, 32)           10624     \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 500, 32)           3104      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 250, 32)           0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 8000)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 8001      \n",
            "=================================================================\n",
            "Total params: 521,729\n",
            "Trainable params: 521,729\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zcYLP8iP5Dez",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Compiliamo il modello ed eseguiamo l'addestramento per 10 epoche."
      ]
    },
    {
      "metadata": {
        "id": "gaEiXE0348ZU",
        "colab_type": "code",
        "outputId": "6c77b351-3f67-47b4-d2f0-7e272eec42ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        }
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, batch_size=512, validation_split=0.2, epochs=5)\n",
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 20000 samples, validate on 5000 samples\n",
            "Epoch 1/5\n",
            "20000/20000 [==============================] - 97s 5ms/step - loss: 0.6040 - acc: 0.6483 - val_loss: 0.5227 - val_acc: 0.7448\n",
            "Epoch 2/5\n",
            "20000/20000 [==============================] - 95s 5ms/step - loss: 0.3583 - acc: 0.8484 - val_loss: 0.4274 - val_acc: 0.8076\n",
            "Epoch 3/5\n",
            "20000/20000 [==============================] - 96s 5ms/step - loss: 0.2919 - acc: 0.8831 - val_loss: 0.3154 - val_acc: 0.8778\n",
            "Epoch 4/5\n",
            "20000/20000 [==============================] - 95s 5ms/step - loss: 0.2413 - acc: 0.9054 - val_loss: 0.2789 - val_acc: 0.8904\n",
            "Epoch 5/5\n",
            "20000/20000 [==============================] - 95s 5ms/step - loss: 0.2107 - acc: 0.9185 - val_loss: 0.2897 - val_acc: 0.8908\n",
            "25000/25000 [==============================] - 48s 2ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.30027052153110506, 0.88164]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "eW4Hjx7lfEWo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Modello 3: Da convololuzionale a ricorrente\n",
        "L'architettura della rete sarà la seguente:\n",
        "1. Il primo strato esegue l'embedding creando 50 embedding vectors per le 10.000 parole nel nostro dizionario.\n",
        "2. Il secondo strato è uno strato convoluzionale che usa 32 filtri di dimensione 3x3 per estrarre features dall'embedding.\n",
        "3. Il terzo strato riduce la dimensione delle features map eseguendo il max pooling con una pool size di 2x2.\n",
        "4. Il quarto strato è lo strato ricorrente (LSTM), per ridurre l'overfitting eseguiamo il dropout sull'input disattivando il 40% dei nodi.\n",
        "5. Il quinto strato calcola l'output della rete.\n",
        "\n",
        "In precedenza, per problemi di computer vision, abbiamo utilizzato la classe Conv2D di Keras per creare uno strato convoluzionale, questo strato prende in input un tensore (ti ricordo che un'immagine è rappresentata come un tensore le cui dimensioni sono altezza dell'immagine, larghezza dell'immagine e canali), questa volta il singolo esempio è una matrice composta dai word vectors delle varie parole che compono la frase, quindi dovremo utilizzare la classe Conv1D."
      ]
    },
    {
      "metadata": {
        "id": "4S7eDkqhe3-g",
        "colab_type": "code",
        "outputId": "e52175b1-a309-4c62-d6dd-98c0ec95e96e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Embedding, LSTM\n",
        "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(num_words, 50))\n",
        "model.add(Conv1D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(LSTM(32, dropout=0.4))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 50)          500000    \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, None, 32)          4832      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, None, 32)          0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 32)                8320      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 513,185\n",
            "Trainable params: 513,185\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aVcL96iVjGHZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Compiliamo il modello ed eseguiamo l'addestramento per 10 epoche."
      ]
    },
    {
      "metadata": {
        "id": "Ts4mnFOyfOlj",
        "colab_type": "code",
        "outputId": "7538e6e1-ab9a-482a-f3f1-6e40f2437b9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        }
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, batch_size=512, validation_split=0.2, epochs=5)\n",
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 20000 samples, validate on 5000 samples\n",
            "Epoch 1/5\n",
            "20000/20000 [==============================] - 54s 3ms/step - loss: 0.6425 - acc: 0.6269 - val_loss: 0.4521 - val_acc: 0.8152\n",
            "Epoch 2/5\n",
            "20000/20000 [==============================] - 53s 3ms/step - loss: 0.4325 - acc: 0.8062 - val_loss: 0.4439 - val_acc: 0.7962\n",
            "Epoch 3/5\n",
            "20000/20000 [==============================] - 53s 3ms/step - loss: 0.3350 - acc: 0.8593 - val_loss: 0.3137 - val_acc: 0.8748\n",
            "Epoch 4/5\n",
            "20000/20000 [==============================] - 53s 3ms/step - loss: 0.2806 - acc: 0.8859 - val_loss: 0.2885 - val_acc: 0.8822\n",
            "Epoch 5/5\n",
            "20000/20000 [==============================] - 53s 3ms/step - loss: 0.2457 - acc: 0.9044 - val_loss: 0.2613 - val_acc: 0.8944\n",
            "25000/25000 [==============================] - 24s 980us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2801623426914215, 0.88612]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "6QxhigwLf7dW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Come vedi, questo approccio ibrido in cui abbiamo combinato uno strato convoluzionale con uno strato ricorrente ci ha portato al miglior risultato che abbiamo ottenuto fin'ora."
      ]
    }
  ]
}